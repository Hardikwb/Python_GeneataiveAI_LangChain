{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2391d27",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### LangChain Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14be63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa9b569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# os.environ[\"GEMINI_API_KEY\"]=os.getenv(\"GEMINI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8525ae7",
   "metadata": {},
   "source": [
    "### Generative AI Application Using Gemini Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48bcfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Generaticve AI Application\n",
    "response=model.invoke(\"Write an essay on AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d059a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229bff56",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.usage_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924fd758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GEMINI_API_KEY\"]=os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model=init_chat_model(\"google_genai:gemini-2.5-flash-lite\")\n",
    "response=model.invoke(\"Write me a contrasting paragraph on langchain\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dc7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "response=model.invoke(\"Write me a contrasting paragraph on RAG App\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d8b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa565e68",
   "metadata": {},
   "source": [
    "### Generative AI Model using GROQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9b4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model=init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "response=model.invoke(\"Write an essay on Agentic AI\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ad6bf",
   "metadata": {},
   "source": [
    "- qwen/qwen3-32b is used for reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9484ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen/qwen3-32b\")\n",
    "response=model.invoke(\"Why Parrots Talk? \")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79214100",
   "metadata": {},
   "source": [
    "### Streaming \n",
    "Thinking and displaying the code like chatgpt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e696f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in model.stream(\"Write an essay in 150 words? \"):\n",
    "    print(chunk.text,end=\"\")\n",
    "    # print(chunk.text,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010f3ab",
   "metadata": {},
   "source": [
    "Batch ->\n",
    "Collection of requests so that it will improve the performance and reduce cost as processing done in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee84c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses=model.batch(\n",
    "    [\n",
    "        \"What's difference between RAG and Fine-tuning?\",\n",
    "        \"What's difference between Agents and Agentsic-AI?\",\n",
    "        \"What's the scope of webdevelopment in 2026?\",\n",
    "        \"From where to learn APP develpoment?\",\n",
    "        \"What's the scope of AI in 2026?\",\n",
    "        \"Which is better claude or gemini or anthropic?\"\n",
    "    ],\n",
    "    config={\n",
    "        \"max_concurrency\":6 # Limit to 5 parallel requests\n",
    "    }\n",
    ")\n",
    "for response in responses:\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

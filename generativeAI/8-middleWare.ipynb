{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ca197d",
   "metadata": {},
   "source": [
    "## MiddleWare:=>\n",
    "MidlleWare provides a way to more tightly control waht happen inside the agent.\n",
    "MiddleWare is useful for the following:\n",
    "- Tracking agent behaviour with loging,analytics and debugging\n",
    "- Transforming prompts,tools selection and output formatting\n",
    "- Adding retries, fallbacks and early termination logic\n",
    "- Applying rate limits,guardrails and PII detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dcfaae",
   "metadata": {},
   "source": [
    "https://docs.langchain.com/oss/python/langchain/middleware/built-in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea3c8a",
   "metadata": {},
   "source": [
    "Analogy -> Agent and client are chatting and we have memoe=ry for that \n",
    "but after sometime chat become large so for this we use Conversation Summariser middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5dbc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"GEMINI_API_KEY\"]=os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f94f13",
   "metadata": {},
   "source": [
    "Summarisation MiddleWare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91d441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages.utils import message_chunk_to_message\n",
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "agent=create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "    # When 10 or more chat summarise and keep last 4 chats  \n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "        model=\"groq:llama-3.1-8b-instant\",\n",
    "        trigger=(\"messages\",10),    \n",
    "        keep=(\"messages\",4)\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fb18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Run with thread id\n",
    "config={\"configurable\":{\"thread_id\":\"test-1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a63ecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative test data\n",
    "questions = [\n",
    "    \"What is 2+2?\",\n",
    "    \"What is 10*5?\",\n",
    "    \"What is 100/4?\",\n",
    "    \"What is 15-7?\",\n",
    "    \"What is 3*3?\",\n",
    "    \"What is 4*4?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    response=agent.invoke({\"messages\":[HumanMessage(content=q)]},config)\n",
    "    print(f\"Messages: {response}\")\n",
    "    print(f\"Messages: {len(response['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5eabc",
   "metadata": {},
   "source": [
    "### Using Token Size via Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98deed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiohttp.web_middlewares import middleware\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool\n",
    "@tool\n",
    "def search_hotels(city: str) -> str:\n",
    "    \"\"\"Search hotels - returns long response to use more tokens.\"\"\"\n",
    "    return f\"\"\"Hotels in {city}:\n",
    "    1. Grand Hotel - 5 star, $350/night, spa, pool, gym\n",
    "    2. City Inn - 4 star, $180/night, business center\n",
    "    3. Budget Stay - 3 star, $75/night, free wifi\"\"\"\n",
    "\n",
    "agent=create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\",\n",
    "    tools=[search_hotels],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            # model=\"groq:llama-3.1-8b-instant\",\n",
    "            model = \"groq:llama-3.1-70b-versatile\",\n",
    "            trigger=(\"tokens\",550),\n",
    "            keep=(\"tokens\",200),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "config={\"configurable\":{\"thread_id\":\"test-1\"}}\n",
    "# if here we are usinf it,this means using the same memory for the all the thing nd token will summarise\n",
    "# If use in next block then each city has different memory  \n",
    "\n",
    "def count_tokens(messages):\n",
    "    total_char=sum(len(n.content) for n in messages)\n",
    "    return total_char//4  # 4 char => 1 token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80773ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test\n",
    "cities = [\"Paris\", \"London\", \"Tokyo\", \"New York\", \"Dubai\", \"Singapore\"]\n",
    "\n",
    "for city in cities:\n",
    "    # create different memory for every place\n",
    "    # config={\"configurable\":{\"thread_id\":f\"test-{city}\"}}\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=f\"Find hotels in {city}\")]},\n",
    "        config\n",
    "        )\n",
    "    \n",
    "    tokens = count_tokens(response[\"messages\"])\n",
    "    print(f\"{city}: ~{tokens} tokens, {len(response['messages'])} messages\")\n",
    "    print(f\"{(response['messages'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a340cf84",
   "metadata": {},
   "source": [
    "Example -> With reference to the fractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b979c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "@tool\n",
    "def search_hotels(city: str) -> str:\n",
    "    \"\"\"Search hotels.\"\"\"\n",
    "    return f\"Hotels in {city}: Grand Hotel $350, City Inn $180, Budget Stay $75\"\n",
    "\n",
    "# LOW fraction for testing!\n",
    "agent = create_agent(\n",
    "    model=\"groq:llama-3.3-70b-versatile\", \n",
    "    tools=[search_hotels],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    system_prompt=\"You are a hotel assistant. Use ONLY the 'search_hotels' tool. Do not use external search.\",\n",
    "    middleware=[\n",
    "        #  This doesn't as don't have token limit so \n",
    "        # SummarizationMiddleware(\n",
    "        # model=\"groq:llama-3.1-70b-versatile\",\n",
    "        #     trigger=(\"fraction\", 0.005),  # 0.5% = ~640 tokens\n",
    "        #     keep=(\"fraction\", 0.002),     # 0.2% = ~256 tokens\n",
    "        # ),\n",
    "        SummarizationMiddleware(\n",
    "            model=\"groq:llama-3.1-8b-instant\",\n",
    "            # Trigger summarization at 640 tokens\n",
    "            trigger=(\"tokens\", 640), \n",
    "            # Keep at least 6 messages to preserve tool-response pairs\n",
    "            keep=(\"messages\", 6),    \n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"test-1\"}}\n",
    "\n",
    "# Token counter\n",
    "def count_tokens(messages):\n",
    "    return sum(len(str(m.content)) for m in messages) // 4\n",
    "\n",
    "# Test\n",
    "cities = [\"Paris\", \"London\", \"Tokyo\", \"New York\", \"Dubai\", \"Singapore\"]\n",
    "\n",
    "for city in cities:\n",
    "    response = agent.invoke(\n",
    "        {\"messages\": [HumanMessage(content=f\"Hotels in {city}\")]},\n",
    "        config\n",
    "    )\n",
    "    tokens = count_tokens(response[\"messages\"])\n",
    "    fraction = tokens / 128000  # gpt-4o-mini context\n",
    "    print(f\"{city}: ~{tokens} tokens ({fraction:.4%}), {len(response['messages'])} msgs\")\n",
    "    print(response['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "In thr above there might be error as  model's attempt to call a tool \n",
    "and the tools registered with the agent. Specifically, your Groq model\n",
    "is attempting to use a tool named brave_search (likely due to \n",
    "internal knowledge or a pre-trained bias for searching), but your create_agent only has search_hotels in its toolset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48e64b4",
   "metadata": {},
   "source": [
    "### Human in the Loop MiddleWare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d87a999",
   "metadata": {},
   "source": [
    "Pause agent execution for human approval, editing, or rejection of tool calls before they execute. \n",
    "\n",
    "Human-in-the-loop is useful for the following:\n",
    "\n",
    "- High-stakes operations requiring human approval (e.g. database writes, financial transactions).\n",
    "- Compliance workflows where human oversight is mandatory.\n",
    "- Long-running conversations where human feedback guides the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "7c9dd02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "\n",
    "# mock function in software testing is a fake, \n",
    "# controllable version of a real function\n",
    "\n",
    "def read_email_tool(email_id:str)->str:\n",
    "    \"\"\"Mock function to read an email by its ID.\"\"\"\n",
    "    return f\"Email content for ID: {email_id}\"\n",
    "\n",
    "def send_email_tool(recipient:str,subject:str,body:str)->str:\n",
    "    \"\"\"Mock function to send an email by its ID.\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject {subject} and body {body}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "agent=create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\",\n",
    "    tools=[send_email_tool,read_email_tool],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(   \n",
    "        interrupt_on={\n",
    "            \"send_email_tool\": {\"allowed_decisions\": [\"approve\", \"reject\",\"edit\"]},\n",
    "            \"read_email_tool\": False,\n",
    "            # No interruption\n",
    "        }\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0063224",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test-approve\"}}\n",
    "# Step 1: Request\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Send email to john@test.com with subject 'Hello' and body 'How are you?'\")]},\n",
    "    config=config\n",
    ")\n",
    "# print(result)\n",
    "print(result['__interrupt__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5b7c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "# Step 2: Approve\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"⏸️ Paused! Approving...\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        Command(\n",
    "            resume={\n",
    "                \"decisions\": [\n",
    "                    {\"type\": \"approve\"}\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Result: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65f40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "# Step 2: Reject\n",
    "if \"__interrupt__\" in result:\n",
    "    print(\"⏸️ Paused! Approving...\")\n",
    "    \n",
    "    result = agent.invoke(\n",
    "        Command(\n",
    "            resume={\n",
    "                \"decisions\": [\n",
    "                    {\"type\": \"reject\"}\n",
    "                ]\n",
    "            }\n",
    "        ),\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Result: {result['messages'][-1].content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ab117",
   "metadata": {},
   "source": [
    "## Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0a989b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "agent=create_agent(\n",
    "    model=\"groq:llama-3.1-8b-instant\",\n",
    "    tools=[send_email_tool,read_email_tool],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(   \n",
    "        interrupt_on={\n",
    "            \"send_email_tool\": {\"allowed_decisions\": [\"approve\", \"reject\",\"edit\"]},\n",
    "            \"read_email_tool\": False,\n",
    "            # No interruption\n",
    "        }\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "85d6e4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"test-edit\"}}\n",
    "\n",
    "# Step 1: Request (with wrong info)\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Send email to wrong@email.com with subject 'Test' and body 'Hello'\")]},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "719ee977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"Send email to wrong@email.com with subject 'Test' and body 'Hello'\", additional_kwargs={}, response_metadata={}, id='eceeb23f-50b3-4a08-8f99-2cbad895f4c0'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'xqea5nmrr', 'function': {'arguments': '{\"body\":\"Hello\",\"recipient\":\"wrong@email.com\",\"subject\":\"Test\"}', 'name': 'send_email_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 313, 'total_tokens': 343, 'completion_time': 0.030698407, 'completion_tokens_details': None, 'prompt_time': 0.473867629, 'prompt_tokens_details': None, 'queue_time': 0.069045209, 'total_time': 0.504566036}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bd1e9-8757-7140-bbf1-8e74e28a3f6f-0', tool_calls=[{'name': 'send_email_tool', 'args': {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}, 'id': 'xqea5nmrr', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 313, 'output_tokens': 30, 'total_tokens': 343})], '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'send_email_tool', 'args': {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}, 'description': \"Tool execution requires approval\\n\\nTool: send_email_tool\\nArgs: {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}\"}], 'review_configs': [{'action_name': 'send_email_tool', 'allowed_decisions': ['approve', 'reject', 'edit']}]}, id='cd6e4102c124a56217353c5f9cce7c92')]}\n",
      "[Interrupt(value={'action_requests': [{'name': 'send_email_tool', 'args': {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}, 'description': \"Tool execution requires approval\\n\\nTool: send_email_tool\\nArgs: {'body': 'Hello', 'recipient': 'wrong@email.com', 'subject': 'Test'}\"}], 'review_configs': [{'action_name': 'send_email_tool', 'allowed_decisions': ['approve', 'reject', 'edit']}]}, id='cd6e4102c124a56217353c5f9cce7c92')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(result)\n",
    "print(result['__interrupt__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e521544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏸️ Paused! Editing...\n",
      "✏️ Result: \n"
     ]
    }
   ],
   "source": [
    "#  Error while doing check this !!!!!!!!!!!\n",
    "\n",
    "# # Step 2: Edit and approve\n",
    "# if \"__interrupt__\" in result:\n",
    "#     print(\"⏸️ Paused! Editing...\")\n",
    "    \n",
    "#     result = agent.invoke(\n",
    "#         Command(\n",
    "#             resume={\n",
    "#                 \"decisions\": [\n",
    "#                     {\n",
    "#                         \"type\": \"edit\",\n",
    "#                         \"edited_action\": {\n",
    "#                             \"name\": \"send_email_tool\",\n",
    "#                             \"args\": {\n",
    "#                                 \"recipient\": \"correct@email.com\",\n",
    "#                                 \"subject\": \"Corrected subject\",\n",
    "#                                 \"body\": \"This was edited by human before sending\"\n",
    "#                             }\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ),\n",
    "#         config=config\n",
    "#     )\n",
    "\n",
    "\n",
    "#     print(result)\n",
    "#     print(f\"✏️ Result: {result['messages'][-1].content}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

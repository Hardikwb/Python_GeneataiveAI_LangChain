{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c739a6c3",
   "metadata": {},
   "source": [
    "Tools =>\n",
    "Models can make requestthat perform tasks sucha s fetching from the database,serching the web or running the code. The toos are the pairing of :\n",
    "\n",
    "1. A schema, including the name of the tool and the description of the tool or argument definitions (JSON schema)\n",
    "\n",
    "2. A function that implements the tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f509d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is January 19, 2024\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "# model=model = init_chat_model(\"groq:llama-3.1-8b-instant\")\n",
    "model=model = init_chat_model(\"groq:llama-3.3-70b-versatile\")\n",
    "response=model.invoke(\"What today's date\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32a619ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def get_weather(location:str)->str:\n",
    "    \"\"\"Get the weather at a location\"\"\"\n",
    "    return f\"It's sunny in {location}\"\n",
    "\n",
    "\n",
    "model_with_tools=model.bind_tools([get_weather])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f07ad153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'sjsa0cmam', 'function': {'arguments': '{\"location\":\"Delhi\"}', 'name': 'get_weather'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 219, 'total_tokens': 234, 'completion_time': 0.054582421, 'completion_tokens_details': None, 'prompt_time': 0.011037085, 'prompt_tokens_details': None, 'queue_time': 0.056601105, 'total_time': 0.065619506}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_c06d5113ec', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bd6c3-a410-7e13-b807-21dbc87b6098-0' tool_calls=[{'name': 'get_weather', 'args': {'location': 'Delhi'}, 'id': 'sjsa0cmam', 'type': 'tool_call'}] invalid_tool_calls=[] usage_metadata={'input_tokens': 219, 'output_tokens': 15, 'total_tokens': 234}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'get_weather',\n",
       "  'args': {'location': 'Delhi'},\n",
       "  'id': 'sjsa0cmam',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=model_with_tools.invoke(\"What is the weather in Delhi?\")\n",
    "print(response)\n",
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad16ac0",
   "metadata": {},
   "source": [
    "### Tool Execution Loop\n",
    "-- For refernce see the image how actually work\n",
    "-- Step 1: User input \n",
    "-- Step 2: Best tool selection and tool execution\n",
    "-- Step 3: Result processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe64031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Model generates tool calls\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather in Banglore?\"}]\n",
    "ai_msg = model_with_tools.invoke(messages)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# Step 2: Execute tools and collect results\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    # Execute the tool with the generated arguments\n",
    "    tool_result = get_weather.invoke(tool_call)\n",
    "    messages.append(tool_result)    \n",
    "\n",
    "# Step 3: Pass results back to model for final response\n",
    "final_response = model_with_tools.invoke(messages)\n",
    "print(final_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a09416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': \"What's the weather in Banglore?\"},\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'vmrcvh9ph', 'function': {'arguments': '{\"location\":\"Bangalore\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 220, 'total_tokens': 235, 'completion_time': 0.045525699, 'completion_tokens_details': None, 'prompt_time': 0.010654922, 'prompt_tokens_details': None, 'queue_time': 0.056488868, 'total_time': 0.056180621}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_dae98b5ecb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019bd6c3-a574-7ff0-96ad-c64240fa496d-0', tool_calls=[{'name': 'get_weather', 'args': {'location': 'Bangalore'}, 'id': 'vmrcvh9ph', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 220, 'output_tokens': 15, 'total_tokens': 235}),\n",
       " ToolMessage(content=\"It's sunny in Bangalore\", name='get_weather', tool_call_id='vmrcvh9ph')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc2495f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 32768, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x0000026E618AED10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000026E618AEC20>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'get_weather', 'description': 'Get the weather at a location', 'parameters': {'properties': {'location': {'type': 'string'}}, 'required': ['location'], 'type': 'object'}}}]}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
